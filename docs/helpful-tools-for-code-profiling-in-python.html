<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>IT Blog | Helpful tools for code profiling in Python</title>
    <meta name="description" content="Professional blog about interesting issues in software and data engineering, data science and other similar topics related to IT created by David Salac.">
    <meta name="keywords" content="Data Visualisation, Profiling, Python, Design, Performance">
    <meta name="author" content="David Salac">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link href="https://fonts.googleapis.com/css2?family=Playfair+Display:ital,wght@0,400;0,700;1,400;1,700&display=swap" rel="stylesheet">
    <link rel="icon" href="favicon.ico">
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <div id="container">
        <nav>
            <a href="/" id="logo">
                <span id="icon">&nbsp;</span>
                IT Blog
            </a>
            
<ul>
    
        <li>
            <a href="/">HOME</a>
        </li>
    
        <li>
            <a href="about.html">About</a>
        </li>
    
        <li>
            <a href="contact.html">Contact</a>
        </li>
    
        <li>
            <a href="https://www.github.com/david-salac/">My GitHub</a>
        </li>
    
</ul>

        </nav>
        <section>
            <main>
                <div id="page-content">
                    
<header>
    <h1>Helpful tools for code profiling in Python</h1>
    
        <span class="date">★ Posted on April 16, 2020</span>
    
</header>
<article>
    
        <div class="illustration" style="background-image: url('images/profiling_big.jpg')"></div>
    
    <div class="content">
        <p class="lead">Code profiling is one of the most important parts of the code optimisation process. Generally speaking, it is the program analysis where we are mainly interested in memory usage and time complexity of the program (or each of its parts). We can also be interested in how often we use some function (or how often we call it, what is the latency). There are a lot of principles and tools to perform these tasks. This article is mainly focused on stack tracing, line-by-line code analysis tools, and function call graphs.</p>

<h2>Stack trace (aka stack backtrace or backtrace) sampling</h2>
<p>Stack trace sampling represents one of the fundamental principles of program profiling. The basic principle is that the algorithm sample program's stack (stack trace) in some reasonable frequency. In the end, we can analyse the running time of each block and its memory usage.</p>
<p>Consider the following code (which is massively ineffective):</p>
<pre class="code"><code>def c(input):
    out = 0
    for i in range(4000):
        out += i * 7 * input
    return out


def b(input):
    out = 0
    for i in range(4000):
        out += i * 5 * input
    out += 5 * c(input)
    return out


def a(input):
    out = 0
    for i in range(8000):
        out += i * 3
    out += i * 3 * b(input)
    return out
</code>
</pre>
<p>A simplified stack of the program (that calls the function 'a') would follow the logic:</p>
<pre class="code"><code>[() <- beginning of the code]
[(a) <- function 'a' is called]
[(a, b) <- function 'a' call the function 'b']
[(a, b, c) <- function 'b' call the function 'c']
[(a, b) <- function 'c' returns the result to 'b']
[(a) <- function 'b' returns the result to 'a']
[() <- function 'a' returns a result]</code></pre>
<p>This stack is simplified because there are also many other sub-operations (arithmetic operators, print statements, loops, etc.), but it captures the main purpose of the stack.</p>

<h3>Visualisation of the stack trace sampling (for running time)</h3>
<p>If we are interested in performance optimisation, we need to see the time consumption of each block. The figure typically looks like this:</p>

<figure>
    <img src="images/profile_abc.png" alt="Figure 1: Logic of stack-trace">
    <figcaption>Figure 1: Logic of stack-trace</figcaption>
</figure>

<p>There is a time on the horizontal axis and the stack depth on the vertical one (in this case, going down) in this figure.</p>

<h3>How to plot figures like this in Python (cProfile, snakeviz, vprof)</h3>
<p>Python has a built-in profiler called cProfile. This profiler documents the running time of each block in the program (alas, not the memory usage). It can be called directly using the command:</p>
<code>python -m cProfile -o {OUTPUT}.dat {PROGRAM}.py</code>
<p>where the <code>{OUTPUT}</code> should be replaced by the path to the output data file and the <code>{PROGAM}</code> is the script that is the subject of the profiling.</p>
<p>There are many tools for the visualisation of the outputs. Arguably the most popular one is called snakeviz. It can be installed using pip (<code>pip install snakeviz</code>). It is a web application visualising the profiler output (received by cProfile) as an interactive graph. To call the SnakeViz, use simply the command:</p>

<pre class="code"><code>snakeviz {OUTPUT}.dat</code></pre>

<p>Output window of the SnakeViz looks like this:</p>

<figure>
    <img src="images/snakeviz.png" alt="Figure 2: Snakeviz output">
    <figcaption>Figure 2: Snakeviz output</figcaption>
</figure>

<p>Another very popular tool that does the same is called vprof. It can be again installed using pip (pip install vprof) and called using logic:</p>

<pre class="code"><code>vprof -c cmh "{PROGRAM}.py"</code></pre>

<h3>What do we want to achieve?</h3>
<p>Our main objective during the optimisation process is to shrink all the blocks as much as possible. Optimally in both dimensions (not to have too many sub-procedures called, and have the shortest running time for each).</p>

<h3>Memory stack trace sampling</h3>
<p>There is currently no equivalent tool in Python for visualisation of memory usage in the stack trace sampling logic when it comes to memory profiling. The only option is to use the line-by-line analysis. Closest to this is the package guppy3 presented below.</p>

<h2>Line-by-line analysis</h2>
<p>This type of analysis is a kind of cavemen approach. We basically measure each line's memory usage and running time in our code. In this case, one must be aware of the impact that measuring itself has on the measured data (line-by-line analysis is susceptible). The output of memory profiling is typically just a table containing line numbers and matching values.</p>

<pre class="code"><code>Line #    Mem usage    Increment   Line Contents
================================================
     5     14.3 MiB     14.3 MiB   @memory_profiler.profile
     6                             def profiled_fn():
     7     14.3 MiB      0.0 MiB       a(9)
</code></pre>

<h3>Memory profiling in Python (package memory-profiler)</h3>
<p>The output of line-by-line memory profiling is the vector that contains the value of used memory for each line of measured code. In Python, a library called memory-profiler can be easily installed by pip (<code>pip install memory-profiler</code>). The simplest model is to profile concrete function using the decorator "profile":</p>

<pre class="code"><code>import memory_profiler

from application import a

@memory_profiler.profile
def profiled_fn():
    a(9)


if __name__ == '__main__':
    profiled_fn()</code></pre>

<p>The output of this profiling is in the table shown above.</p>

<p>Slightly more complex usage of the memory-profiler (usable for further processing) is to use the method "memory_usage":</p>

<pre class="code"><code>import memory_profiler

from application import a, b, c


def measured_function(arg):
    print(a(arg))
    print(b(arg))
    print(c(arg))


# Measure the memory usage
mem_usage: list = memory_profiler.memory_usage((measured_function, (5, )))</code></pre>

<p>This function returns an array containing each line's memory usage (indexed from 0). Using the memory_usage function is incredibly helpful for analysing the code memory requirements for different inputs.</p>
<p>It is good to know that Python requires some mandatory memory usage of about 100 MB (this has to be considered a constant). Memory usage accepts two parameters, one is the pointer to the function, and another one is the tuple of arguments.</p>

<h3>Visualisation of the line-by-line memory profiling in Python</h3>
<p>After receiving the vector with values, you can use all standard approaches for plotting graphs in Python (like pyplot). Slightly more complex visualisation is available in the vprof (described above). If you choose to use vprof, you, unfortunately, cannot scale the problem by any argument (it just shows you the memory consumption line by line of script that you have called).</p>

<h3>Package guppy3 for advanced memory profiling</h3>
<p>Package guppy3 (installable via PIP: <code>pip install guppy3</code>) represents a slightly more sophisticated approach for analysing the program memory usage. It shows a more in-depth analysis of the heap state, including the objects' data types (unfortunately, only the basic type are reflected). You can as well use the complex API to access all measured values. To use guppy3, follow the logic:</p>

<pre class="code"><code>import guppy

from application import a, b

# Do some logic
a(9)
# Create a point for the analysis
point_0 = guppy.hpy()
# Do different logic
b(7)
# Creates another point:
point_1 = guppy.hpy()

# Print the analysis
print(point_0.heap())
print(point_1.heap())</code></pre>

<p>where <code>point_0 = hpy()</code> creates a point where the analysis of the heap is committed. For printing the analysis, you can call the function <code>point_0.heap()</code> on the object (or you can use deeper analysis tools described in the documentation on GitHub). Typical output looks like this:</p>

<pre class="code"><code>Partition of a set of 39738 objects. Total size = 4574417 bytes.
 Index  Count   %     Size   % Cumulative  % Kind (class / dict of class)
     0  10694  27   976147  21    976147  21 str
     1   9808  25   718032  16   1694179  37 tuple
     2    557   1   456456  10   2150635  47 type
     3   2441   6   352832   8   2503467  55 types.CodeType
     4   4854  12   336978   7   2840445  62 bytes
     5   2304   6   313344   7   3153789  69 function
     6    557   1   268024   6   3421813  75 dict of type
     7    248   1   184800   4   3606613  79 dict (no owner)
     8     99   0   183152   4   3789765  83 dict of module
     9    288   1    96256   2   3886021  85 set
<115 more rows. Type e.g. '_.more' to view.></code></pre>

<p>As you can see, guppy3 covers everything available in the memory_profile package plus offers slightly deeper inside.</p>

<h2>Function dynamic call graphs</h2>
<p>A call graph (aka call multigraph) shows the flow of the application. Basically, it visualises what each function call based on a given input. It is an incredibly helpful tool for simplifying the code (reducing the number of function calls). The typical flow looks like this:</p>

<figure>
    <img src="images/call_graph.png" alt="Figure 3: Call-graph example">
    <figcaption>Figure 3: Call-graph output example</figcaption>
</figure>

<h3>Creating the call graph figure in Python</h3>
<p>Although it seems to be a trivial task (which it surprisingly is not), there are no robust tools that can create a call graph. The package closest to this goal is pycallgraph2 (pip install pycallgraph2). However, to make it work, it also requires a system package called graphviz (on Debian installable via apt install graphviz).</p>

<p>To create the graph, you need to commit:</p>

<pre class="code"><code>pycallgraph graphviz -- {PROGRAM}.py</code></pre>

<p>The script generates the PNG file (pycallgraph.png) that looks like the graph illustrated in the figure above. Another way to use pycallgraph is to use it inside the source code.</p>

<pre class="code"><code>from pycallgraph2 import PyCallGraph

from pycallgraph2.output import GraphvizOutput

from application import a

with PyCallGraph(output=GraphvizOutput()):
    # Code to profile:
    a(9)</code></pre>

<p>Real problems are typically so complicated that generated figure is not easily readable (generated objects are massive). The script is also very susceptible and cannot handle many useful things (multithreading and multitasking, many external libraries, etc.).</p>

<h2>Other types of profiling</h2>
<p>So far, only a generic type of code profiling has been discussed. However, there might be other essential metrics depending on the application type. One of the common things for web application is to measure the number of database hits - meaning how many times does application access the database server for a specific request (or set of requests). This information is important because every request is delayed by latency when accessing the database server. Similar essential matric is the number of input and output operations on disk (or through the network) - for the same reason (each IO operation has its latency). This matric can be measured using presented tools (focusing on IO operation calls). There always is a trade-off between reading or writing more but less often versus the opposite.</p>

<h2>Summary</h2>
<p>There are many similar tools for code profiling. It is, however, always good to bear in mind that measuring itself changes a code behaviour (always true). This article summarises some essential tools available in Python for code profiling. The performance (run time) profiling is cProfile + snakeviz or vprof. The profiling of memory usage is the package memory-profiler and guppy3. When it comes to the dynamic call graphs, it is mainly the package pycallgraph2. All presented packages are available through PIP (the pycallgraph2 also requires one system package).</p>

<h2>Related GIT repo</h2>
<p>All used source codes are available in the REPO: <a href="https://github.com/david-salac/python-memory-profiling">GIT repo</a></p>
<p>See the <a href="https://github.com/zhuyifei1999/guppy3">guppy3 documentation on GitHub</a></p>


        
            <span class="tag-cloud">❋ Tags:
                <a href="tag-data-visualisation.html">Data Visualisation</a>
                <a href="tag-profiling.html">Profiling</a>
                <a href="tag-python.html">Python</a>
                <a href="tag-design.html">Design</a>
                <a href="tag-performance.html">Performance</a>
                
            </span>
        
    </div>
</article>
                </div>

                <aside>
                    
<h3>Recent posts</h3>
<div class="separator"></div>
<ul>
    
        <li><a href="practical-aspects-of-requirements-engineering.html">Practical aspects of requirements engineering</a></li>
    
        <li><a href="technical-possibilities-in-binary-serialization-and-rpc.html">Technical possibilities in binary serialization and RPC</a></li>
    
        <li><a href="two-universes-in-the-big-data-environment.html">Two universes in the big data environment</a></li>
    
        <li><a href="most-common-use-cases-for-nosql-databases.html">Most common use cases for NoSQL databases</a></li>
    
        <li><a href="practical-aspects-of-asynchronous-programming-in-python.html">Practical aspects of asynchronous programming in Python</a></li>
    
</ul>

                    
<h3>Tags</h3>
<div class="separator"></div>
<ul class="tag-cloud">
    
        <li><a href="tag-design.html ">Design</a></li>
    
        <li><a href="tag-python.html ">Python</a></li>
    
        <li><a href="tag-performance.html ">Performance</a></li>
    
        <li><a href="tag-programming.html ">Programming</a></li>
    
        <li><a href="tag-essentials.html ">Essentials</a></li>
    
</ul>
<div class="clear"></div>

                    <h3>About</h3>
<div class="separator"></div>
<p>Professional blog about interesting issues in software and data engineering, data science and other similar topics related to IT created by David Salac.<p>Generated using <a href="http://www.crinita.com/">Crinita</a> in version 1.1.0.</p></p>
                </aside>
                <div class="clear"></div>
            </main>
            <footer>
                <p><a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" src="images/creative_commons.png"></a><br>All the content is licensed under a <br><a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.</p>
            </footer>
        </section>
    </div>
</body>
</html>